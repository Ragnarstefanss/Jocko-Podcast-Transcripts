{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install git+https://github.com/openai/whisper.git "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !yt-dlp -f 'ba' -x --audio-format mp3 <URL>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import whisper\n",
    "import pathlib\n",
    "import os\n",
    "\n",
    "# CODE FROM: https://www.codingforentrepreneurs.com/blog/getting-started-with-openai-whisper/\n",
    "def timedelta_to_videotime(delta):\n",
    "  \"\"\"\n",
    "  Here's a janky way to format a \n",
    "  datetime.timedelta to match \n",
    "  the format of vtt timecodes. \n",
    "  \"\"\"\n",
    "  parts = delta.split(\":\")\n",
    "  if len(parts[0]) == 1:\n",
    "    parts[0] = f\"0{parts[0]}\"\n",
    "  new_data = \":\".join(parts)\n",
    "  parts2 = new_data.split(\".\")\n",
    "  if len(parts2) == 1:\n",
    "    parts2.append(\"000\")\n",
    "  elif len(parts2) == 2:\n",
    "    parts2[1] = parts2[1][:2]\n",
    "  final_data = \".\".join(parts2)\n",
    "  return final_data\n",
    "\n",
    "\n",
    "def whisper_segments_to_vtt_data(result_segments):\n",
    "  \"\"\"\n",
    "  This function iterates through all whisper\n",
    "  segements to format them into WebVTT.\n",
    "  \"\"\"\n",
    "  data = \"WEBVTT\\n\\n\"\n",
    "  for idx, segment in enumerate(result_segments):\n",
    "    num = idx + 1\n",
    "    data += f\"{num}\\n\"\n",
    "    start_ = datetime.timedelta(seconds=segment.get('start'))\n",
    "    start_ = timedelta_to_videotime(str(start_))\n",
    "    end_ = datetime.timedelta(seconds=segment.get('end'))\n",
    "    end_ = timedelta_to_videotime(str(end_))\n",
    "    data += f\"{start_} --> {end_}\\n\"\n",
    "    text = segment.get('text').strip()\n",
    "    data += f\"{text}\\n\\n\"\n",
    "  return data\n",
    "\n",
    "\n",
    "whisper_model = whisper.load_model(\"large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf .ipynb_checkpoints\n",
    "AUDIO_FILES_PATH = \"./\"\n",
    "\n",
    "# This file should primarily be moved inside a folder with all of the audio files \n",
    "# which is why the path to full text and to captions should be the directory before that audio folder \n",
    "path_to_where_full_text_goes = \"../full_text_output/\"\n",
    "path_to_where_captions_go = \"../caption_output/\"\n",
    "\n",
    "for file in os.listdir(AUDIO_FILES_PATH):\n",
    "    # make sure file is an image\n",
    "    if file.endswith(('.webm', '.mp3')):\n",
    "        audio_title = file.split(\".\")[0]\n",
    "        print(audio_title)\n",
    "        \n",
    "        #transcribe audio\n",
    "        transcription = whisper_model.transcribe(file)\n",
    "        with open(path_to_where_full_text_goes+audio_title+\".txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(transcription[\"text\"])\n",
    "        \n",
    "        #captions\n",
    "        caption_data = whisper_segments_to_vtt_data(transcription['segments']) #print(caption_data) \n",
    "        with open(path_to_where_captions_go+audio_title+\".vtt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(caption_data)\n",
    "        \n",
    "        print(\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eb60acc68106785d00a40fb3b1b3b80d861e6f0b0d60f9d8440fa3d46ca2822c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
